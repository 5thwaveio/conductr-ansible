--- 
- name: Provision and configure a ConductR cluster on AWS
  hosts: localhost
  connection: local
  gather_facts: False

  vars_files:
    - "{{ VARS_FILE }}"
    
  tasks:
    - name: Launch Seed
      local_action:
        module: ec2
        image: "{{ IMAGE }}"
        instance_type: "{{ INSTANCE_TYPE }}"
        keypair: "{{ KEYPAIR }}"
        region: "{{ EC2_REGION }}"
        group_id: "{{ NODE_SECURITY_GROUP }}"
        vpc_subnet_id: "{{ SUBNET_SEED }}"
        assign_public_ip: yes
        instance_tags:
          Name: "{{ TAG_NAME }}"
          Role: Seed Node
        count: 1
        volumes:
          - device_name: /dev/sda1
            device_type: "{{VOL_TYPE }}"
            volume_size: "{{ VOL_SIZE }}"
            delete_on_termination: true
        wait: yes
      register: ec2

    - debug: msg="Seed node {{ ec2.instances[0].private_ip }} --- {{ ec2.instances[0].public_dns_name }}"

    - name: Add seed to seeds_public
      add_host:
        groupname: "seeds_public"
        hostname: "{{ ec2.instances[0].public_ip }}"

    - name: Add seed to seeds_private
      add_host:
        groupname: "seeds_private"
        hostname: "{{ ec2.instances[0].private_ip }}"

    - name: Add public ip to nodes
      add_host:
        groupname: "nodes"
        hostname: "{{ ec2.instances[0].public_ip }}"

    - name: Launch Nodes
      local_action:
        module: ec2
        image: "{{ IMAGE }}"
        instance_type: "{{ INSTANCE_TYPE }}"
        keypair: "{{ KEYPAIR }}"
        region: "{{ EC2_REGION }}"
        group_id: "{{ NODE_SECURITY_GROUP }}"
        vpc_subnet_id: "{{ item }}"
        assign_public_ip: yes
        instance_tags:
          Name: "{{ TAG_NAME }}"
          Role: Node
        count: 1
        volumes:
          - device_name: /dev/sda1
            device_type: "{{ VOL_TYPE }}"
            volume_size: "{{ VOL_SIZE }}"
            delete_on_termination: true
        wait: yes
      register: ec2
      with_items:
        - "{{ SUBNET1 }}"
        - "{{ SUBNET2 }}"

    - name: Add public ip to nodes
      add_host:
        groupname: "nodes"
        hostname: "{{ item.instances[0].public_ip }}"
      with_items: "{{ ec2.results }}"

    - name: Wait for SSH to come up
      wait_for:
        host: "{{ item.instances[0].public_dns_name }}"
        port: 22
        delay: 60
        timeout: 320
        state: started
      with_items: "{{ ec2.results }}"

- name: Setup ConductR
  hosts: nodes
  user: "{{ REMOTE_USER }}"
  gather_facts: False
  sudo: True

  vars:
# These are the default ConductR roles - these roles may be overridden within the VARS_FILE
    CONDUCTR_AGENT_ROLES:
      - web
      - haproxy
      - elasticsearch

  vars_files:
    - "{{ VARS_FILE }}"

  tasks:
    - include: python/tasks/main.yml
    - include: java/tasks/main.yml
    - include: docker/tasks/main.yml
      when: "{{ INSTALL_DOCKER }} == true"
    - include: ntp/tasks/main.yml
    - include: haproxy/tasks/main.yml
    - include: conductr/tasks/install-core.yml
    - include: conductr/tasks/install-agent.yml

- name: Install ConductR HAProxy from the seed node
  hosts: seeds_public
  user: "{{ REMOTE_USER }}"
  gather_facts: True
  sudo: True

  vars_files:
    - "{{ VARS_FILE }}"

  tasks:
    - include: "bundle/tasks/install-conductr-haproxy.yml"

- name: Register ConductR with ELB
  hosts: nodes
  user: "{{ REMOTE_USER }}"
  gather_facts: True
  sudo: True

  vars:
# Get these from env to workaround https://github.com/ansible/ansible/issues/10638
    aws_access_key:  "{{ lookup('env','AWS_ACCESS_KEY_ID') }}"
    aws_secret_key:  "{{ lookup('env','AWS_SECRET_ACCESS_KEY') }}"

  vars_files:
    - "{{ VARS_FILE }}"

  tasks:
    - include: conductr/tasks/register-elb.yml
